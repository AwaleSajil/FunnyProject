{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sawale/Documents/FunnyProject/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizer, \n",
    "    RobertaForSequenceClassification, \n",
    "    RobertaConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    TrainingArguments, \n",
    "    Trainer, \n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import evaluate\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "MAX_LEN = 512\n",
    "TARGET_COLUMNS = ['humor', 'offensiveness', 'sentiment']\n",
    "NUM_TARGETS = len(TARGET_COLUMNS)\n",
    "MODEL_CHECKPOINT = \"FacebookAI/roberta-base\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback to record loss history\n",
    "class LossHistory(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.train_losses = []  # to store (global_step, training loss)\n",
    "        self.eval_losses = []   # to store (global_step, evaluation loss)\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        # Log training loss if available\n",
    "        if logs is not None and \"loss\" in logs:\n",
    "            self.train_losses.append((state.global_step, logs[\"loss\"]))\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        # Log evaluation loss if available\n",
    "        if metrics is not None and \"eval_loss\" in metrics:\n",
    "            self.eval_losses.append((state.global_step, metrics[\"eval_loss\"]))\n",
    "\n",
    "def plot_loss_history(loss_history, save_path=\"loss_plot.png\"):\n",
    "    \"\"\"\n",
    "    Plots the training and evaluation loss curves stored in the loss_history callback.\n",
    "    \"\"\"\n",
    "    if loss_history.train_losses:\n",
    "        train_steps, train_loss_values = zip(*loss_history.train_losses)\n",
    "    else:\n",
    "        train_steps, train_loss_values = [], []\n",
    "    \n",
    "    if loss_history.eval_losses:\n",
    "        eval_steps, eval_loss_values = zip(*loss_history.eval_losses)\n",
    "    else:\n",
    "        eval_steps, eval_loss_values = [], []\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_steps, train_loss_values, label=\"Training Loss\", marker='o')\n",
    "    plt.plot(eval_steps, eval_loss_values, label=\"Evaluation Loss\", marker='o')\n",
    "    plt.xlabel(\"Global Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Evaluation Loss Over Time\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    print(f\"Loss plot saved as '{save_path}'.\")\n",
    "\n",
    "# Function to load data from a parquet file and process targets\n",
    "def load_data(file_path, nrows=None):\n",
    "    # Load dataset from a Parquet file\n",
    "    df = pd.read_parquet(file_path)\n",
    "    if nrows:\n",
    "        df = df.head(nrows)\n",
    "    \n",
    "    # Assume that columns for our 3 metrics already exist.\n",
    "    # For classification, cast them as integers.\n",
    "    df[TARGET_COLUMNS] = df[TARGET_COLUMNS].astype(int)\n",
    "    \n",
    "    # Ensure jokes are strings\n",
    "    df['joke'] = df['joke'].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Custom dataset class for classification\n",
    "class JokeDataset(Dataset):\n",
    "    def __init__(self, jokes, targets, tokenizer, max_len):\n",
    "        self.jokes = jokes\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.jokes)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        joke = str(self.jokes[idx])\n",
    "        # Convert target values to float for BCEWithLogitsLoss (they are binary: 0 or 1)\n",
    "        targets = np.array(self.targets[idx]).astype(np.float32)\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            joke,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(targets, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Define the compute_metrics function for multi-label classification\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # Apply sigmoid to get probabilities\n",
    "    sigmoid_preds = 1 / (1 + np.exp(-predictions))\n",
    "    # Threshold probabilities at 0.5 for binary predictions\n",
    "    binary_preds = (sigmoid_preds > 0.5).astype(int)\n",
    "    \n",
    "    # Compute precision, recall, and f1 scores for each target\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    for i in range(NUM_TARGETS):\n",
    "        precision = precision_score(labels[:, i], binary_preds[:, i], zero_division=0)\n",
    "        recall = recall_score(labels[:, i], binary_preds[:, i], zero_division=0)\n",
    "        f1 = f1_score(labels[:, i], binary_preds[:, i], zero_division=0)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "    \n",
    "    results = {\n",
    "        \"precision\": np.mean(precision_list),\n",
    "        \"recall\": np.mean(recall_list),\n",
    "        \"f1\": np.mean(f1_list)\n",
    "    }\n",
    "    for i, target in enumerate(TARGET_COLUMNS):\n",
    "        results[f\"precision_{target}\"] = precision_list[i]\n",
    "        results[f\"recall_{target}\"] = recall_list[i]\n",
    "        results[f\"f1_{target}\"] = f1_list[i]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main(data_path, nrows):\n",
    "    # Load data\n",
    "    print(f\"Loading data from {data_path}\")\n",
    "    df = load_data(data_path, nrows=nrows)\n",
    "\n",
    "    # Split data into train, validation, and test sets (80%, 10%, 10%)\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED)\n",
    "    \n",
    "    print(f\"Train set: {len(train_df)} samples\")\n",
    "    print(f\"Validation set: {len(val_df)} samples\")\n",
    "    print(f\"Test set: {len(test_df)} samples\")\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = JokeDataset(\n",
    "        jokes=train_df['joke'].values,\n",
    "        targets=train_df[TARGET_COLUMNS].values,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=MAX_LEN\n",
    "    )\n",
    "    \n",
    "    val_dataset = JokeDataset(\n",
    "        jokes=val_df['joke'].values,\n",
    "        targets=val_df[TARGET_COLUMNS].values,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=MAX_LEN\n",
    "    )\n",
    "    \n",
    "    test_dataset = JokeDataset(\n",
    "        jokes=test_df['joke'].values,\n",
    "        targets=test_df[TARGET_COLUMNS].values,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=MAX_LEN\n",
    "    )\n",
    "    \n",
    "    # Configure the model for multi-label classification\n",
    "    config = AutoConfig.from_pretrained(MODEL_CHECKPOINT)\n",
    "    config.num_labels = NUM_TARGETS\n",
    "    config.problem_type = \"multi_label_classification\"\n",
    "    \n",
    "    # Add id to label and label to id mappings to the model config\n",
    "    id2label = {i: label for i, label in enumerate(TARGET_COLUMNS)}\n",
    "    label2id = {label: i for i, label in enumerate(TARGET_COLUMNS)}\n",
    "    config.id2label = id2label\n",
    "    config.label2id = label2id\n",
    "    print(\"Mapping id to label:\", config.id2label)\n",
    "    print(\"Mapping label to id:\", config.label2id)\n",
    "    \n",
    "    # Initialize model; using AutoModelForSequenceClassification sets up BCEWithLogitsLoss internally.\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_CHECKPOINT,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # Optionally, freeze the base model layers if you want to fine-tune only the classification head\n",
    "    for param in model.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Instantiate loss history callback\n",
    "    loss_history = LossHistory()\n",
    "    \n",
    "    # Set up training arguments (note that we now use \"f1\" as our metric for best model)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=500,\n",
    "        eval_steps=500,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        save_total_limit=2,\n",
    "        learning_rate=5.0e-5\n",
    "        # fp16=True,  # Uncomment if using mixed precision\n",
    "    )\n",
    "    \n",
    "    # Set up Trainer with early stopping\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=1), loss_history]\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train()\n",
    "    plot_loss_history(loss_history, save_path=\"loss_plot.png\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"Evaluating on test set...\")\n",
    "    test_results = trainer.evaluate(test_dataset)\n",
    "    print(\"Test results:\", test_results)\n",
    "    \n",
    "    # Save model\n",
    "    print(\"Saving model...\")\n",
    "    trainer.save_model(\"./joke_classification_model\")\n",
    "    \n",
    "    # Generate classification report for Train set\n",
    "    print(\"Generating classification report for the Train set...\")\n",
    "    train_predictions = trainer.predict(train_dataset)\n",
    "    train_logits = train_predictions.predictions\n",
    "    train_labels = train_predictions.label_ids\n",
    "    # Apply sigmoid and threshold to get binary predictions\n",
    "    train_sigmoid = 1 / (1 + np.exp(-train_logits))\n",
    "    train_binary_preds = (train_sigmoid > 0.5).astype(int)\n",
    "    \n",
    "    train_report = classification_report(train_labels, train_binary_preds, target_names=TARGET_COLUMNS, zero_division=0)\n",
    "    print(\"Train Classification Report:\")\n",
    "    print(train_report)\n",
    "    \n",
    "    # Generate classification report for Test set\n",
    "    print(\"Generating classification report for the Test set...\")\n",
    "    test_predictions = trainer.predict(test_dataset)\n",
    "    test_logits = test_predictions.predictions\n",
    "    test_labels = test_predictions.label_ids\n",
    "    test_sigmoid = 1 / (1 + np.exp(-test_logits))\n",
    "    test_binary_preds = (test_sigmoid > 0.5).astype(int)\n",
    "    \n",
    "    test_report = classification_report(test_labels, test_binary_preds, target_names=TARGET_COLUMNS, zero_division=0)\n",
    "    print(\"Test Classification Report:\")\n",
    "    print(test_report)\n",
    "    \n",
    "    # (Optional) Save predictions/actuals for further analysis\n",
    "    print(\"Sample binary predictions (first 5):\", test_binary_preds[:5])\n",
    "    \n",
    "    # Return results for further use if needed\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"test_results\": test_results,\n",
    "        \"train_report\": train_report,\n",
    "        \"test_report\": test_report,\n",
    "        \"raw_predictions\": test_logits,\n",
    "        \"binary_predictions\": test_binary_preds,\n",
    "        \"actual_values\": test_labels\n",
    "    }\n",
    "\n",
    "\n",
    "def predict_joke_ratings(joke_text, model_path=\"./joke_classification_model\"):\n",
    "    \"\"\"\n",
    "    Use the trained classification model to predict ratings for a new joke.\n",
    "    \n",
    "    Args:\n",
    "        joke_text (str): The text of the joke to rate.\n",
    "        model_path (str): Path to the saved model.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Predicted ratings (0/1) for each metric, with labels from the model configuration.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "    # Load the model configuration and extract the id2label mapping\n",
    "    config = AutoConfig.from_pretrained(model_path)\n",
    "    id2label = config.id2label  # id2label should be a dict with integer keys mapping to target labels\n",
    "    \n",
    "    # Load the model using the updated configuration\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize the joke text\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        joke_text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=encoding['input_ids'],\n",
    "            attention_mask=encoding['attention_mask']\n",
    "        )\n",
    "        logits = outputs.logits.cpu().numpy()[0]\n",
    "    \n",
    "    # Convert logits to probabilities and then to binary predictions\n",
    "    sigmoid_probs = 1 / (1 + np.exp(-logits))\n",
    "    binary_preds = (sigmoid_probs > 0.5).astype(int)\n",
    "    \n",
    "    # Use the id2label mapping from the model configuration to form the results\n",
    "    results = {id2label[i]: int(pred) for i, pred in enumerate(binary_preds)}\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/sawale/Documents/FunnyProject/data/labeled_jokes_classification.parquet\n",
      "Train set: 456 samples\n",
      "Validation set: 57 samples\n",
      "Test set: 58 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping id to label: {0: 'humor', 1: 'offensiveness', 2: 'sentiment'}\n",
      "Mapping label to id: {'humor': 0, 'offensiveness': 1, 'sentiment': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sawale/Documents/FunnyProject/.venv/lib/python3.11/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 00:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss plot saved as 'loss_plot.png'.\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.6486513614654541, 'eval_precision': 0.43678160919540227, 'eval_recall': 0.6666666666666666, 'eval_f1': 0.5276903599204196, 'eval_precision_humor': 0.6724137931034483, 'eval_recall_humor': 1.0, 'eval_f1_humor': 0.8041237113402062, 'eval_precision_offensiveness': 0.0, 'eval_recall_offensiveness': 0.0, 'eval_f1_offensiveness': 0.0, 'eval_precision_sentiment': 0.6379310344827587, 'eval_recall_sentiment': 1.0, 'eval_f1_sentiment': 0.7789473684210526, 'eval_runtime': 1.5853, 'eval_samples_per_second': 36.586, 'eval_steps_per_second': 0.631, 'epoch': 3.0}\n",
      "Saving model...\n",
      "Generating classification report for the Train set...\n",
      "Train Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        humor       0.63      1.00      0.78       289\n",
      "offensiveness       0.00      0.00      0.00        84\n",
      "    sentiment       0.60      1.00      0.75       273\n",
      "\n",
      "    micro avg       0.62      0.87      0.72       646\n",
      "    macro avg       0.41      0.67      0.51       646\n",
      " weighted avg       0.54      0.87      0.66       646\n",
      "  samples avg       0.62      0.66      0.63       646\n",
      "\n",
      "Generating classification report for the Test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        humor       0.67      1.00      0.80        39\n",
      "offensiveness       0.00      0.00      0.00         8\n",
      "    sentiment       0.64      1.00      0.78        37\n",
      "\n",
      "    micro avg       0.66      0.90      0.76        84\n",
      "    macro avg       0.44      0.67      0.53        84\n",
      " weighted avg       0.59      0.90      0.72        84\n",
      "  samples avg       0.66      0.67      0.66        84\n",
      "\n",
      "Sample binary predictions (first 5): [[1 0 1]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [1 0 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace with your actual file path\n",
    "data_path = \"/Users/sawale/Documents/FunnyProject/data/labeled_jokes_classification.parquet\"\n",
    "results = main(data_path, nrows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example prediction:\n",
      "humor: 1\n",
      "offensiveness: 0\n",
      "sentiment: 1\n"
     ]
    }
   ],
   "source": [
    "# Example of using the model with a new joke\n",
    "print(\"\\nExample prediction:\")\n",
    "sample_joke = \"Why don't scientists trust atoms? Because they make up everything!\"\n",
    "predicted_ratings = predict_joke_ratings(sample_joke)\n",
    "for dimension, rating in predicted_ratings.items():\n",
    "    print(f\"{dimension}: {rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example prediction:\n",
      "humor: 1.00\n",
      "offensiveness: 0.00\n",
      "sentiment: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Example of using the model with a new joke\n",
    "print(\"\\nExample prediction:\")\n",
    "sample_joke = \"hello.\"\n",
    "predictions = predict_joke_ratings(sample_joke)\n",
    "for dimension, score in predictions.items():\n",
    "    print(f\"{dimension}: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
