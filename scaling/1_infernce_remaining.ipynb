{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMNS = ['humor', 'offensiveness', 'sentiment']\n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labelled_data(file_path, nrows=None):\n",
    "    # Load dataset from a Parquet file\n",
    "    df = pd.read_parquet(file_path)\n",
    "    if nrows:\n",
    "        df = df.head(nrows)\n",
    "    \n",
    "    # Cast the target columns to int for classification purposes.\n",
    "    df[TARGET_COLUMNS] = df[TARGET_COLUMNS].astype(int)\n",
    "    \n",
    "    # Drop rows where any value in the target columns isn't 0 or 1.\n",
    "    # This creates a boolean mask that checks for binary values.\n",
    "    df = df[df[TARGET_COLUMNS].isin([0, 1]).all(axis=1)]\n",
    "\n",
    "    df[TARGET_COLUMNS] = df[TARGET_COLUMNS].astype(float)\n",
    "    \n",
    "    # Ensure that the 'joke' column is of type string.\n",
    "    df['joke'] = df['joke'].astype(str)\n",
    "\n",
    "    # drop duplicates\n",
    "    df = df.drop_duplicates(subset=['joke'])\n",
    "\n",
    "    df = df[df['joke'].apply(lambda x: isinstance(x, str))]\n",
    "    # drop empty jokes\n",
    "    df = df[df['joke'].str.strip() != '']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2240996/949333606.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unlabeled_df.drop(columns=TARGET_COLUMNS, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/rJokesData/data/preprocessed.csv.gz\")\n",
    "labeled_df = load_labelled_data(\"../data/labeled_jokes_classification_mistral:latest.parquet\")\n",
    "\n",
    "data = data[[\"date\", \"joke\", \"score\"]]\n",
    "data['date'] = pd.to_datetime(data['date'], unit='s')\n",
    "\n",
    "data[TARGET_COLUMNS] = None\n",
    "\n",
    "# this replaces every column in data for which there is a row in labeled_df\n",
    "data.loc[labeled_df.index] = labeled_df\n",
    "\n",
    "unlabeled_df = data[data[TARGET_COLUMNS].isnull().all(axis=1)]\n",
    "unlabeled_df.drop(columns=TARGET_COLUMNS, inplace=True)\n",
    "unlabeled_df = unlabeled_df[unlabeled_df['joke'].apply(lambda x: isinstance(x, str))]\n",
    "# unlabeled_df = unlabeled_df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rhome/sawale/FunnyProject/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 4048/4048 [2:19:30<00:00,  2.07s/it]  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "\n",
    "def predict_joke_ratings_bulk(\n",
    "    jokes: list[str],\n",
    "    model_path: str = \"../traning_encoder/joke_classification_model\",\n",
    "    batch_size: int = 128,\n",
    "    threshold: float = 0.5,\n",
    "    device: str = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Predict binary ratings for multiple jokes in bulk.\n",
    "\n",
    "    Args:\n",
    "        jokes: List of joke strings.\n",
    "        model_path: Path or checkpoint name of your saved model.\n",
    "        batch_size: How many jokes to process per forward-pass.\n",
    "        threshold: Probability threshold for converting to 0/1.\n",
    "        device: 'cuda' or 'cpu'. If None, automatically picks cuda if available.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame of shape (len(jokes), n_labels) with columns = label names.\n",
    "    \"\"\"\n",
    "    # 1. Set up device\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # 2. Load tokenizer, config, id2label, and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    config = AutoConfig.from_pretrained(model_path)\n",
    "    id2label = config.id2label  # e.g. {0: \"humor\", 1: \"offensiveness\", 2: \"sentiment\"}\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    # 3. Process in batches\n",
    "    for i in tqdm(range(0, len(jokes), batch_size)):\n",
    "        batch_texts = jokes[i : i + batch_size]\n",
    "        # 3a. Tokenize\n",
    "        encodings = tokenizer(\n",
    "            batch_texts,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            max_length=MAX_LEN,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        # 3b. Forward pass\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encodings)\n",
    "            logits = outputs.logits  # shape (batch_size, n_labels)\n",
    "        # 3c. Sigmoid → probs → binary\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        batch_preds = (probs > threshold).astype(int)\n",
    "        all_preds.append(batch_preds)\n",
    "\n",
    "    # 4. Concatenate and build DataFrame\n",
    "    all_preds = np.vstack(all_preds)  # shape (len(jokes), n_labels)\n",
    "    # Map columns via id2label in correct order\n",
    "    columns = [id2label[i] for i in range(all_preds.shape[1])]\n",
    "    return pd.DataFrame(all_preds, columns=columns)\n",
    "\n",
    "\n",
    "# Suppose you have a DataFrame `df` with a 'joke' column:\n",
    "jokes = unlabeled_df[\"joke\"].tolist()\n",
    "preds_df = predict_joke_ratings_bulk(jokes)\n",
    "for col in preds_df.columns:\n",
    "    unlabeled_df[col] = preds_df[col].values\n",
    "prediction_df = unlabeled_df\n",
    "# prediction_df = pd.concat([unlabeled_df, preds_df], axis=1)\n",
    "\n",
    "prediction_df[\"source\"] = \"predicted\"\n",
    "labeled_df[\"source\"] = \"label\"\n",
    "\n",
    "df_combined = pd.concat([labeled_df, prediction_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((518124, 7), (55278, 7), (573402, 7))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df.shape, labeled_df.shape, df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>joke</th>\n",
       "      <th>score</th>\n",
       "      <th>humor</th>\n",
       "      <th>offensiveness</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-07 02:57:10</td>\n",
       "      <td>Anti-dandruff shampoo with sulfur causes hair ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-23 17:59:44</td>\n",
       "      <td>I use to be addicted to the Hokie Pokie.... bu...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-24 13:09:05</td>\n",
       "      <td>A man goes into a job interview A man goes int...</td>\n",
       "      <td>11956.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-20 02:35:30</td>\n",
       "      <td>What is the one food that diminishes a woman's...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-19 20:21:42</td>\n",
       "      <td>Rick Astley will let you borrow any movie from...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573397</th>\n",
       "      <td>2019-12-31 23:31:07</td>\n",
       "      <td>A German joke A German is driving his car in B...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573398</th>\n",
       "      <td>2019-12-31 23:37:28</td>\n",
       "      <td>My wife has asked me to help her with her diet...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573399</th>\n",
       "      <td>2019-12-31 23:45:39</td>\n",
       "      <td>Me arguing with my dad Me: I hate you motherfu...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573400</th>\n",
       "      <td>2019-12-31 23:54:35</td>\n",
       "      <td>Early I know it's early, but a very happy new ...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573401</th>\n",
       "      <td>2019-12-31 23:58:52</td>\n",
       "      <td>If you make chili with impossible burger, you ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573402 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date                                               joke  \\\n",
       "0      2019-10-07 02:57:10  Anti-dandruff shampoo with sulfur causes hair ...   \n",
       "1      2015-03-23 17:59:44  I use to be addicted to the Hokie Pokie.... bu...   \n",
       "2      2016-03-24 13:09:05  A man goes into a job interview A man goes int...   \n",
       "3      2015-02-20 02:35:30  What is the one food that diminishes a woman's...   \n",
       "4      2016-06-19 20:21:42  Rick Astley will let you borrow any movie from...   \n",
       "...                    ...                                                ...   \n",
       "573397 2019-12-31 23:31:07  A German joke A German is driving his car in B...   \n",
       "573398 2019-12-31 23:37:28  My wife has asked me to help her with her diet...   \n",
       "573399 2019-12-31 23:45:39  Me arguing with my dad Me: I hate you motherfu...   \n",
       "573400 2019-12-31 23:54:35  Early I know it's early, but a very happy new ...   \n",
       "573401 2019-12-31 23:58:52  If you make chili with impossible burger, you ...   \n",
       "\n",
       "          score  humor  offensiveness  sentiment     source  \n",
       "0           1.0    1.0            0.0        1.0      label  \n",
       "1           3.0    1.0            0.0        1.0      label  \n",
       "2       11956.0    1.0            0.0        1.0      label  \n",
       "3          76.0    1.0            0.0        0.0      label  \n",
       "4          81.0    1.0            0.0        1.0      label  \n",
       "...         ...    ...            ...        ...        ...  \n",
       "573397     16.0    1.0            0.0        1.0  predicted  \n",
       "573398      4.0    1.0            0.0        1.0  predicted  \n",
       "573399      2.0    0.0            0.0        1.0  predicted  \n",
       "573400     21.0    1.0            0.0        1.0  predicted  \n",
       "573401      1.0    1.0            0.0        1.0  predicted  \n",
       "\n",
       "[573402 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_parquet(\"classified_data.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_non_str = any(not isinstance(x, str) for x in jokes)\n",
    "has_non_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "bad_indices = [i for i, x in enumerate(jokes) if not isinstance(x, str)]\n",
    "bad_values  = [x for x in jokes           if not isinstance(x, str)]\n",
    "\n",
    "print(bad_indices)  # → [1, 3, 4]\n",
    "print(bad_values)   # → [None, 123, nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
